{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from loguru import logger\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\", UserWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use the mads_datasets package (see [github](https://github.com/raoulg/mads_datasets) for more details) which I created for these lessons to give everyone easy access to the datasets we use for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetType.FLOWERS\n",
      "DatasetType.IMDB\n",
      "DatasetType.GESTURES\n",
      "DatasetType.FASHION\n",
      "DatasetType.SUNSPOTS\n",
      "DatasetType.IRIS\n",
      "DatasetType.PENGUINS\n",
      "DatasetType.FAVORITA\n",
      "DatasetType.SECURE\n"
     ]
    }
   ],
   "source": [
    "from mads_datasets import DatasetFactoryProvider, DatasetType\n",
    "from mltrainer.preprocessors import BasePreprocessor\n",
    "\n",
    "for dataset in DatasetType:\n",
    "    print(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a few datasets. For images, we can use FLOWERS (~3000 photos of flowers in 5 categories) and FASHION (60k fashion icons 28x28 pixels big)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets start with our good'ol MNIST."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-11-07 10:46:12.362\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmads_datasets.base\u001b[0m:\u001b[36mdownload_data\u001b[0m:\u001b[36m121\u001b[0m - \u001b[1mFolder already exists at C:\\Users\\NvanOort\\.cache\\mads_datasets\\fashionmnist\u001b[0m\n",
      "\u001b[32m2025-11-07 10:46:12.362\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmads_datasets.base\u001b[0m:\u001b[36mdownload_data\u001b[0m:\u001b[36m124\u001b[0m - \u001b[1mFile already exists at C:\\Users\\NvanOort\\.cache\\mads_datasets\\fashionmnist\\fashionmnist.pt\u001b[0m\n",
      "c:\\Users\\NvanOort\\Code\\MADS\\DLDEPL\\portfolio-NTvanOort\\.venv\\Lib\\site-packages\\mads_datasets\\factories\\torchfactories.py:71: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  data = torch.load(self.filepath)  # type: ignore\n"
     ]
    }
   ],
   "source": [
    "\n",
    "fashionfactory = DatasetFactoryProvider.create_factory(DatasetType.FASHION)\n",
    "batchsize = 64\n",
    "preprocessor = BasePreprocessor()\n",
    "streamers = fashionfactory.create_datastreamer(batchsize=batchsize, preprocessor=preprocessor)\n",
    "train = streamers[\"train\"]\n",
    "valid = streamers[\"valid\"]\n",
    "trainstreamer = train.stream()\n",
    "validstreamer = valid.stream()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can obtain an item:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([64, 1, 28, 28]), torch.Size([64]))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, y = next(iter(trainstreamer))\n",
    "x.shape, y.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The image follows the channels-first convention: (channel, width, height). The label is an integer.\n",
    "\n",
    "Let's re-use the model we had:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "if torch.backends.mps.is_available() and torch.backends.mps.is_built():\n",
    "    device = torch.device(\"mps\")\n",
    "    print(\"Using MPS\")\n",
    "elif torch.cuda.is_available():\n",
    "    device = \"cuda:0\"\n",
    "    print(\"using cuda\")\n",
    "else:\n",
    "    device = \"cpu\"\n",
    "    print(\"using cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-11-07 10:46:15.004\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m31\u001b[0m - \u001b[1mAggregating activationmap with size torch.Size([6, 6])\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda:0 device\n"
     ]
    }
   ],
   "source": [
    "from torch import nn\n",
    "print(f\"Using {device} device\")\n",
    "\n",
    "# Define model\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self, filters, units1, units2, input_size=(32, 1, 28, 28)):\n",
    "        super().__init__()\n",
    "        self.in_channels = input_size[1]\n",
    "        self.input_size = input_size\n",
    "        self.filters = filters\n",
    "        self.units1 = units1\n",
    "        self.units2 = units2\n",
    "\n",
    "        self.convolutions = nn.Sequential(\n",
    "            nn.Conv2d(self.in_channels, filters, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(filters),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout2d(0.2),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            nn.Conv2d(filters, filters, kernel_size=3, stride=1, padding=0),\n",
    "            nn.BatchNorm2d(filters),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout2d(0.2),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            # nn.Conv2d(filters, filters, kernel_size=3, stride=1, padding=0),\n",
    "            # nn.ReLU(),\n",
    "            # nn.MaxPool2d(kernel_size=2),\n",
    "        )\n",
    "\n",
    "        activation_map_size = self._conv_test(input_size)\n",
    "        logger.info(f\"Aggregating activationmap with size {activation_map_size}\")\n",
    "        self.agg = nn.AvgPool2d(activation_map_size)\n",
    "\n",
    "        self.dense = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(filters, units1),\n",
    "            nn.ReLU(),\n",
    "            # nn.Dropout(0.4),\n",
    "            nn.Linear(units1, units2),\n",
    "            nn.ReLU(),\n",
    "            # nn.Dropout(0.4),\n",
    "            nn.Linear(units2, 10)\n",
    "        )\n",
    "\n",
    "    def _conv_test(self, input_size = (64, 1, 28, 28)):\n",
    "        x = torch.ones(input_size)\n",
    "        x = self.convolutions(x)\n",
    "        return x.shape[-2:]\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.convolutions(x)\n",
    "        x = self.agg(x)\n",
    "        logits = self.dense(x)\n",
    "        return logits\n",
    "\n",
    "model = CNN(filters=64, units1=64, units2=32).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mltrainer.imagemodels import CNNConfig, CNNblocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = CNNConfig(\n",
    "    matrixshape = (28, 28), # every image is 28x28\n",
    "    batchsize = batchsize,\n",
    "    input_channels = 1, # we have black and white images, so only one channel\n",
    "    hidden = 32, # number of filters\n",
    "    kernel_size = 3, # kernel size of the convolution\n",
    "    maxpool = 3, # kernel size of the maxpool\n",
    "    num_layers = 4, # we will stack 4 Convolutional blocks, each with two Conv2d layers\n",
    "    num_classes = 10,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculated matrix size: 9\n",
      "Caluclated flatten size: 288\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'matrixshape': (28, 28),\n",
       " 'batchsize': 64,\n",
       " 'input_channels': 1,\n",
       " 'hidden': 32,\n",
       " 'kernel_size': 3,\n",
       " 'maxpool': 3,\n",
       " 'num_layers': 4,\n",
       " 'num_classes': 10}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = CNNblocks(config)\n",
    "model.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "CNNblocks                                [32, 10]                  --\n",
       "├─ModuleList: 1-1                        --                        --\n",
       "│    └─ConvBlock: 2-1                    [32, 32, 28, 28]          --\n",
       "│    │    └─Sequential: 3-1              [32, 32, 28, 28]          9,568\n",
       "│    └─ConvBlock: 2-2                    [32, 32, 28, 28]          --\n",
       "│    │    └─Sequential: 3-2              [32, 32, 28, 28]          18,496\n",
       "│    └─ReLU: 2-3                         [32, 32, 28, 28]          --\n",
       "│    └─MaxPool2d: 2-4                    [32, 32, 9, 9]            --\n",
       "│    └─ConvBlock: 2-5                    [32, 32, 9, 9]            --\n",
       "│    │    └─Sequential: 3-3              [32, 32, 9, 9]            18,496\n",
       "│    └─ReLU: 2-6                         [32, 32, 9, 9]            --\n",
       "│    └─ConvBlock: 2-7                    [32, 32, 9, 9]            --\n",
       "│    │    └─Sequential: 3-4              [32, 32, 9, 9]            18,496\n",
       "│    └─ReLU: 2-8                         [32, 32, 9, 9]            --\n",
       "│    └─MaxPool2d: 2-9                    [32, 32, 3, 3]            --\n",
       "│    └─ConvBlock: 2-10                   [32, 32, 3, 3]            --\n",
       "│    │    └─Sequential: 3-5              [32, 32, 3, 3]            18,496\n",
       "│    └─ReLU: 2-11                        [32, 32, 3, 3]            --\n",
       "├─Sequential: 1-2                        [32, 10]                  --\n",
       "│    └─Flatten: 2-12                     [32, 288]                 --\n",
       "│    └─Linear: 2-13                      [32, 32]                  9,248\n",
       "│    └─ReLU: 2-14                        [32, 32]                  --\n",
       "│    └─Linear: 2-15                      [32, 10]                  330\n",
       "==========================================================================================\n",
       "Total params: 93,130\n",
       "Trainable params: 93,130\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.MEGABYTES): 805.59\n",
       "==========================================================================================\n",
       "Input size (MB): 0.10\n",
       "Forward/backward pass size (MB): 28.50\n",
       "Params size (MB): 0.37\n",
       "Estimated Total Size (MB): 28.98\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchinfo import summary\n",
    "summary(model, input_size=(32, 1, 28, 28))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And set up the optimizer, loss and accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "from mltrainer import metrics\n",
    "optimizer = optim.Adam\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "accuracy = metrics.Accuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.140625"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yhat = model(x.to(device))\n",
    "accuracy(y.to(device), yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mltrainer import metrics, Trainer, TrainerSettings, ReportTypes\n",
    "settings = TrainerSettings(\n",
    "    epochs=3,\n",
    "    metrics=[accuracy],\n",
    "    logdir=\"demo\",\n",
    "    train_steps=100,\n",
    "    valid_steps=100,\n",
    "    reporttypes=[ReportTypes.TOML],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-10-27 14:46:53.076\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mdir_add_timestamp\u001b[0m:\u001b[36m24\u001b[0m - \u001b[1mLogging to demo\\20251027-144653\u001b[0m\n",
      "\u001b[32m2025-10-27 14:46:56.288\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m68\u001b[0m - \u001b[1mFound earlystop_kwargs in settings.Set to None if you dont want earlystopping.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:01<00:00, 60.43it/s]\n",
      "\u001b[32m2025-10-27 14:46:58.540\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 0 train 1.8107 test 0.9269 metric ['0.6595']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:01<00:00, 77.89it/s]\n",
      "\u001b[32m2025-10-27 14:47:00.399\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 1 train 0.8346 test 0.7319 metric ['0.6945']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:01<00:00, 77.33it/s]\n",
      "\u001b[32m2025-10-27 14:47:02.267\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 2 train 0.7231 test 0.7100 metric ['0.7305']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 3/3 [00:05<00:00,  1.99s/it]\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "            model=model,\n",
    "            settings=settings,\n",
    "            loss_fn=loss_fn,\n",
    "            optimizer=optimizer,\n",
    "            traindataloader=trainstreamer,\n",
    "            validdataloader=validstreamer,\n",
    "            scheduler=optim.lr_scheduler.ReduceLROnPlateau,\n",
    "            device=device,\n",
    "        )\n",
    "trainer.loop()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLflow\n",
    "MLflow is an open-source platform designed to manage the entire Machine Learning (ML) lifecycle, including experimentation, reproducibility, deployment, and governance. It provides a set of APIs and tools to streamline ML workflows, making it easier to track experiments, package code, manage model versions, and deploy models.\n",
    "\n",
    "Reasons to use MLflow over TensorBoard, gin-config, or Ray:\n",
    "\n",
    "- End-to-end ML lifecycle management: While TensorBoard focuses on visualizing model training metrics and gin-config on hyperparameter configuration, MLflow covers a broader range of tasks, such as experiment tracking, model packaging, and deployment.\n",
    "\n",
    "- Framework agnostic: MLflow is not tied to a specific ML framework, making it suitable for projects using different libraries or even multiple libraries.\n",
    "\n",
    "- Model Registry: MLflow provides a centralized model registry, allowing you to version, track, and manage your models, which is not available in TensorBoard or gin-config.\n",
    "\n",
    "- Deployment support: MLflow facilitates model deployment to various platforms, such as local, cloud, or Kubernetes environments, whereas TensorBoard and gin-config are not built for deployment tasks.\n",
    "\n",
    "- Integration with other tools: MLflow integrates with popular tools and platforms like Databricks, AWS, and Azure, making it easy to incorporate into existing workflows.\n",
    "\n",
    "However, the choice between MLflow and other tools like TensorBoard, gin-config, or Ray depends on your specific use case and the scope of the ML workflow you want to manage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_path = \"mlflow_test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/11/07 10:46:38 INFO mlflow.store.db.utils: Creating initial MLflow database tables...\n",
      "2025/11/07 10:46:38 INFO mlflow.store.db.utils: Updating database tables\n",
      "INFO  [alembic.runtime.migration] Context impl SQLiteImpl.\n",
      "INFO  [alembic.runtime.migration] Will assume non-transactional DDL.\n",
      "INFO  [alembic.runtime.migration] Context impl SQLiteImpl.\n",
      "INFO  [alembic.runtime.migration] Will assume non-transactional DDL.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='file:c:/Users/NvanOort/Code/MADS/DLDEPL/portfolio-NTvanOort/2-hypertuning-mlflow/mlruns/1', creation_time=1760812635414, experiment_id='1', last_update_time=1760812635414, lifecycle_stage='active', name='mlflow_test', tags={}>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import mlflow\n",
    "mlflow.set_tracking_uri(\"sqlite:///mlflow.db\")\n",
    "mlflow.set_experiment(experiment_path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the code above, we set the MLflow tracking URI to a local SQLite database file. This is done to configure the storage location for MLflow's experiment tracking data, such as metrics, parameters, and artifacts. By specifying a SQLite database, we enable a lightweight and easy-to-use storage solution for tracking the experiments and their associated information.\n",
    "\n",
    "The line mlflow.set_experiment(\"mnist_convolutions\") sets the active MLflow experiment to \"mnist_convolutions\". This is useful for organizing and grouping your runs, as it allows you to associate the upcoming ML training runs with a specific experiment name, making it easier to search, compare, and analyze the results later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials\n",
    "from hyperopt.pyll import scope"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We import functions and classes from the hyperopt library to perform hyperparameter optimization. This library helps us find the best hyperparameter values for our machine learning model by searching through a defined search space and using optimization algorithms like Tree-structured Parzen Estimator (TPE). The goal is to improve our model's performance by tuning its hyperparameters.\n",
    "\n",
    "Advantages of TPE:\n",
    "\n",
    "- Model-based approach: TPE is a Bayesian optimization method that models the objective function as a probability distribution. It learns from previous evaluations to decide which points in the search space to explore next, making it more efficient in finding optimal hyperparameters.\n",
    "\n",
    "- Exploration-exploitation trade-off: TPE balances the trade-off between exploration (searching in new regions of the search space) and exploitation (refining around the current best points). This can lead to better results in problems with complex search spaces.\n",
    "\n",
    "- Continuous hyperparameter optimization: TPE can handle continuous hyperparameters more naturally, as it builds a probability model to estimate the performance for any given point in the search space.\n",
    "\n",
    "Lets set up an objective function and start logging some usefull things we might want to track:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "modeldir = Path(\"models\").resolve()\n",
    "if not modeldir.exists():\n",
    "    modeldir.mkdir()\n",
    "    print(f\"Created {modeldir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "from mltrainer import metrics, Trainer, TrainerSettings, ReportTypes\n",
    "from datetime import datetime\n",
    "\n",
    "# Define the hyperparameter search space\n",
    "settings = TrainerSettings(\n",
    "    epochs=20,\n",
    "    metrics=[accuracy],\n",
    "    logdir=modeldir,\n",
    "    train_steps=100,\n",
    "    valid_steps=100,\n",
    "    reporttypes=[ReportTypes.MLFLOW, ReportTypes.TOML],\n",
    "    optimizer_kwargs={\"lr\": 0.0015, \"weight_decay\": 1e-4},\n",
    ")\n",
    "\n",
    "\n",
    "# Define the objective function for hyperparameter optimization\n",
    "def objective(params):\n",
    "    # Start a new MLflow run for tracking the experiment\n",
    "    with mlflow.start_run():\n",
    "        # Set MLflow tags to record metadata about the model and developer\n",
    "        mlflow.set_tag(\"model\", \"convnet\")\n",
    "        mlflow.set_tag(\"dev\", \"nick\")\n",
    "        # Log hyperparameters to MLflow\n",
    "        mlflow.log_params(params)\n",
    "        mlflow.log_param(\"batchsize\", f\"{batchsize}\")\n",
    "\n",
    "\n",
    "        # Initialize the optimizer, loss function, and accuracy metric\n",
    "        optimizer = optim.AdamW\n",
    "        loss_fn = torch.nn.CrossEntropyLoss()\n",
    "        accuracy = metrics.Accuracy()\n",
    "        config = CNNConfig(\n",
    "            matrixshape = (28, 28), # every image is 28x28\n",
    "            batchsize = batchsize,\n",
    "            input_channels = 1, # we have black and white images, so only one channel\n",
    "            hidden = params[\"filters\"], # number of filters\n",
    "            kernel_size = params[\"kernel_size\"], # kernel size of the convolution\n",
    "            maxpool = params[\"maxpool\"], # kernel size of the maxpool\n",
    "            num_layers = params[\"num_layers\"], # we will stack 4 Convolutional blocks, each with two Conv2d layers\n",
    "            num_classes = 10,\n",
    "        )\n",
    "\n",
    "        # Instantiate the CNN model with the given hyperparameters\n",
    "        model = CNNblocks(config)\n",
    "        # Train the model using a custom train loop\n",
    "        trainer = Trainer(\n",
    "            model=model,\n",
    "            settings=settings,\n",
    "            loss_fn=loss_fn,\n",
    "            optimizer=optimizer,\n",
    "            traindataloader=trainstreamer,\n",
    "            validdataloader=validstreamer,\n",
    "            scheduler=optim.lr_scheduler.ReduceLROnPlateau,\n",
    "            device=device,\n",
    "        )\n",
    "        trainer.loop()\n",
    "\n",
    "        # Save the trained model with a timestamp\n",
    "        tag = datetime.now().strftime(\"%Y%m%d-%H%M\")\n",
    "        modelpath = modeldir / (tag + \"model.pt\")\n",
    "        torch.save(model, modelpath)\n",
    "\n",
    "        # Log the saved model as an artifact in MLflow\n",
    "        mlflow.log_artifact(local_path=modelpath, artifact_path=\"pytorch_models\")\n",
    "        return {'loss' : trainer.test_loss, 'status': STATUS_OK}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-11-07 11:03:26.536\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mdir_add_timestamp\u001b[0m:\u001b[36m24\u001b[0m - \u001b[1mLogging to C:\\Users\\NvanOort\\Code\\MADS\\DLDEPL\\portfolio-NTvanOort\\2-hypertuning-mlflow\\models\\20251107-110326\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculated matrix size: 196\n",
      "Caluclated flatten size: 12544\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-11-07 11:03:27.296\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m68\u001b[0m - \u001b[1mFound earlystop_kwargs in settings.Set to None if you dont want earlystopping.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:02<00:00, 39.67it/s]\n",
      "\u001b[32m2025-11-07 11:03:30.767\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 0 train 0.9435 test 0.6426 metric ['0.7628']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:02<00:00, 43.18it/s]\n",
      "\u001b[32m2025-11-07 11:03:34.074\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 1 train 0.5239 test 0.5341 metric ['0.8031']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:02<00:00, 43.10it/s]\n",
      "\u001b[32m2025-11-07 11:03:37.398\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 2 train 0.4503 test 0.4498 metric ['0.8394']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:02<00:00, 44.26it/s]\n",
      "\u001b[32m2025-11-07 11:03:40.598\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 3 train 0.3993 test 0.3686 metric ['0.8641']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:02<00:00, 43.69it/s]\n",
      "\u001b[32m2025-11-07 11:03:43.872\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 4 train 0.3763 test 0.3623 metric ['0.8636']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:02<00:00, 43.15it/s]\n",
      "\u001b[32m2025-11-07 11:03:47.175\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 5 train 0.3411 test 0.3622 metric ['0.8612']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:02<00:00, 42.93it/s]\n",
      "\u001b[32m2025-11-07 11:03:50.535\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 6 train 0.3281 test 0.3523 metric ['0.8753']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:02<00:00, 44.37it/s]\n",
      "\u001b[32m2025-11-07 11:03:53.754\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 7 train 0.3169 test 0.3275 metric ['0.8772']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:02<00:00, 43.01it/s]\n",
      "\u001b[32m2025-11-07 11:03:57.051\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 8 train 0.2974 test 0.3248 metric ['0.8828']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:02<00:00, 43.45it/s]\n",
      "\u001b[32m2025-11-07 11:04:00.333\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 9 train 0.2881 test 0.3314 metric ['0.8788']\u001b[0m\n",
      "\u001b[32m2025-11-07 11:04:00.334\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m252\u001b[0m - \u001b[1mbest loss: 0.3248, current loss 0.3314.Counter 1/10.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:02<00:00, 43.00it/s]\n",
      "\u001b[32m2025-11-07 11:04:03.632\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 10 train 0.2862 test 0.3367 metric ['0.8756']\u001b[0m\n",
      "\u001b[32m2025-11-07 11:04:03.638\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m252\u001b[0m - \u001b[1mbest loss: 0.3248, current loss 0.3367.Counter 2/10.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:02<00:00, 43.42it/s]\n",
      "\u001b[32m2025-11-07 11:04:06.965\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 11 train 0.3119 test 0.3086 metric ['0.8800']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:02<00:00, 42.88it/s]\n",
      "\u001b[32m2025-11-07 11:04:10.285\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 12 train 0.2782 test 0.2789 metric ['0.8947']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:02<00:00, 43.22it/s]\n",
      "\u001b[32m2025-11-07 11:04:13.586\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 13 train 0.2730 test 0.2845 metric ['0.9002']\u001b[0m\n",
      "\u001b[32m2025-11-07 11:04:13.590\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m252\u001b[0m - \u001b[1mbest loss: 0.2789, current loss 0.2845.Counter 1/10.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:02<00:00, 42.81it/s]\n",
      "\u001b[32m2025-11-07 11:04:16.906\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 14 train 0.2622 test 0.2668 metric ['0.9022']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:02<00:00, 42.40it/s]\n",
      "\u001b[32m2025-11-07 11:04:20.240\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 15 train 0.2337 test 0.2710 metric ['0.9020']\u001b[0m\n",
      "\u001b[32m2025-11-07 11:04:20.240\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m252\u001b[0m - \u001b[1mbest loss: 0.2668, current loss 0.2710.Counter 1/10.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:02<00:00, 43.34it/s]\n",
      "\u001b[32m2025-11-07 11:04:23.556\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 16 train 0.2232 test 0.2500 metric ['0.9106']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:02<00:00, 43.07it/s]\n",
      "\u001b[32m2025-11-07 11:04:26.887\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 17 train 0.2307 test 0.2920 metric ['0.8908']\u001b[0m\n",
      "\u001b[32m2025-11-07 11:04:26.887\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m252\u001b[0m - \u001b[1mbest loss: 0.2500, current loss 0.2920.Counter 1/10.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:02<00:00, 42.90it/s]\n",
      "\u001b[32m2025-11-07 11:04:30.170\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 18 train 0.2415 test 0.2712 metric ['0.9044']\u001b[0m\n",
      "\u001b[32m2025-11-07 11:04:30.170\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m252\u001b[0m - \u001b[1mbest loss: 0.2500, current loss 0.2712.Counter 2/10.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:02<00:00, 42.79it/s]\n",
      "\u001b[32m2025-11-07 11:04:33.517\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 19 train 0.2302 test 0.2606 metric ['0.9023']\u001b[0m\n",
      "\u001b[32m2025-11-07 11:04:33.517\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m252\u001b[0m - \u001b[1mbest loss: 0.2500, current loss 0.2606.Counter 3/10.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 20/20 [01:06<00:00,  3.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.2606255742907524\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Definieer handmatig je parameters\n",
    "params = {\n",
    "    'filters': 64,\n",
    "    'kernel_size': 3,\n",
    "    'maxpool': 2,\n",
    "    'num_layers': 2\n",
    "}\n",
    "\n",
    "# Roep de objective functie aan\n",
    "result = objective(params)\n",
    "print(f\"Test loss: {result['loss']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See https://hyperopt.github.io/hyperopt/getting-started/search_spaces/ for more information about searchspaces for hyperopt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_space = {\n",
    "    'filters' : scope.int(hp.quniform('filters', 16, 128, 8)),\n",
    "    'kernel_size' : scope.int(hp.quniform('kernel_size', 2, 5, 1)),\n",
    "    'num_layers' : scope.int(hp.quniform('num_layers', 1, 10, 1)),\n",
    "}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define a search space for hyperparameter optimization using Hyperopt. The search space specifies the range and distribution of hyperparameters to explore during the optimization process. This is crucial for finding the optimal set of hyperparameters that yield the best performance for the machine learning model. The search space defined here includes the number of filters in the convolutional layers, and the number of units in two fully connected layers, allowing Hyperopt to find the best combination within the given ranges.\n",
    "\n",
    "\n",
    "Now, finally, let us perform the hyperparameter search using the fmin function from hyperopt. The function takes the following arguments:\n",
    "\n",
    "- `fn=objective`: The objective function to minimize, which is defined earlier to train the model and return the test loss.\n",
    "- `space=search_space`: The search space defined earlier, containing the range of hyperparameters to explore.\n",
    "- `algo=tpe.suggest`: The optimization algorithm to use, in this case, the Tree-structured Parzen Estimator (TPE) method.\n",
    "- `max_evals=10`: The maximum number of function evaluations, i.e., the maximum number of hyperparameter combinations to try.\n",
    "- `trials=Trials()`: A Trials object to store the results of each evaluation.\n",
    "\n",
    "The fmin function searches for the best hyperparameters within the given search space using the TPE algorithm, aiming to minimize the objective function (test loss). Once the optimization process is completed, the best hyperparameters found are stored in the best_result variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculated matrix size: 49                           \n",
      "Caluclated flatten size: 3920                        \n",
      "  0%|          | 0/3 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-11-07 11:15:17.589\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mdir_add_timestamp\u001b[0m:\u001b[36m24\u001b[0m - \u001b[1mLogging to C:\\Users\\NvanOort\\Code\\MADS\\DLDEPL\\portfolio-NTvanOort\\2-hypertuning-mlflow\\models\\20251107-111517\u001b[0m\n",
      "\u001b[32m2025-11-07 11:15:18.373\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m68\u001b[0m - \u001b[1mFound earlystop_kwargs in settings.Set to None if you dont want earlystopping.\u001b[0m\n",
      "  0%|\u001b[38;2;30;71;6m          \u001b[0m| 0/20 [00:00<?, ?it/s]\n",
      "  0%|\u001b[38;2;30;71;6m          \u001b[0m| 0/100 [00:00<?, ?it/s]\u001b[A\n",
      "  0%|\u001b[38;2;30;71;6m          \u001b[0m| 0/100 [00:00<?, ?it/s]\n",
      "  0%|\u001b[38;2;30;71;6m          \u001b[0m| 0/20 [00:00<?, ?it/s]\n",
      "ERROR [hyperopt.fmin] job exception: mat1 and mat2 shapes cannot be multiplied (64x80 and 3920x80)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3 [00:00<?, ?trial/s, best loss=?]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (64x80 and 3920x80)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[28]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m best_result = \u001b[43mfmin\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfn\u001b[49m\u001b[43m=\u001b[49m\u001b[43mobjective\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m    \u001b[49m\u001b[43mspace\u001b[49m\u001b[43m=\u001b[49m\u001b[43msearch_space\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[43malgo\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtpe\u001b[49m\u001b[43m.\u001b[49m\u001b[43msuggest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_evals\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m3\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrials\u001b[49m\u001b[43m=\u001b[49m\u001b[43mTrials\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\NvanOort\\Code\\MADS\\DLDEPL\\portfolio-NTvanOort\\.venv\\Lib\\site-packages\\hyperopt\\fmin.py:540\u001b[39m, in \u001b[36mfmin\u001b[39m\u001b[34m(fn, space, algo, max_evals, timeout, loss_threshold, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin, points_to_evaluate, max_queue_len, show_progressbar, early_stop_fn, trials_save_file)\u001b[39m\n\u001b[32m    537\u001b[39m     fn = __objective_fmin_wrapper(fn)\n\u001b[32m    539\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m allow_trials_fmin \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(trials, \u001b[33m\"\u001b[39m\u001b[33mfmin\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m540\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtrials\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfmin\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    541\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    542\u001b[39m \u001b[43m        \u001b[49m\u001b[43mspace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    543\u001b[39m \u001b[43m        \u001b[49m\u001b[43malgo\u001b[49m\u001b[43m=\u001b[49m\u001b[43malgo\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    544\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmax_evals\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_evals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    545\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    546\u001b[39m \u001b[43m        \u001b[49m\u001b[43mloss_threshold\u001b[49m\u001b[43m=\u001b[49m\u001b[43mloss_threshold\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    547\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmax_queue_len\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_queue_len\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    548\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrstate\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrstate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    549\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpass_expr_memo_ctrl\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpass_expr_memo_ctrl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    550\u001b[39m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    551\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcatch_eval_exceptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcatch_eval_exceptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    552\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreturn_argmin\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_argmin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    553\u001b[39m \u001b[43m        \u001b[49m\u001b[43mshow_progressbar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mshow_progressbar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    554\u001b[39m \u001b[43m        \u001b[49m\u001b[43mearly_stop_fn\u001b[49m\u001b[43m=\u001b[49m\u001b[43mearly_stop_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    555\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrials_save_file\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrials_save_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    556\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    558\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m trials \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    559\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m os.path.exists(trials_save_file):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\NvanOort\\Code\\MADS\\DLDEPL\\portfolio-NTvanOort\\.venv\\Lib\\site-packages\\hyperopt\\base.py:671\u001b[39m, in \u001b[36mTrials.fmin\u001b[39m\u001b[34m(self, fn, space, algo, max_evals, timeout, loss_threshold, max_queue_len, rstate, verbose, pass_expr_memo_ctrl, catch_eval_exceptions, return_argmin, show_progressbar, early_stop_fn, trials_save_file)\u001b[39m\n\u001b[32m    666\u001b[39m \u001b[38;5;66;03m# -- Stop-gap implementation!\u001b[39;00m\n\u001b[32m    667\u001b[39m \u001b[38;5;66;03m#    fmin should have been a Trials method in the first place\u001b[39;00m\n\u001b[32m    668\u001b[39m \u001b[38;5;66;03m#    but for now it's still sitting in another file.\u001b[39;00m\n\u001b[32m    669\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mfmin\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m fmin\n\u001b[32m--> \u001b[39m\u001b[32m671\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfmin\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    672\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    673\u001b[39m \u001b[43m    \u001b[49m\u001b[43mspace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    674\u001b[39m \u001b[43m    \u001b[49m\u001b[43malgo\u001b[49m\u001b[43m=\u001b[49m\u001b[43malgo\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    675\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_evals\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_evals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    676\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    677\u001b[39m \u001b[43m    \u001b[49m\u001b[43mloss_threshold\u001b[49m\u001b[43m=\u001b[49m\u001b[43mloss_threshold\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    678\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrials\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    679\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrstate\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrstate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    680\u001b[39m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    681\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_queue_len\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_queue_len\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    682\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_trials_fmin\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# -- prevent recursion\u001b[39;49;00m\n\u001b[32m    683\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpass_expr_memo_ctrl\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpass_expr_memo_ctrl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    684\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcatch_eval_exceptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcatch_eval_exceptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    685\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreturn_argmin\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_argmin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    686\u001b[39m \u001b[43m    \u001b[49m\u001b[43mshow_progressbar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mshow_progressbar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    687\u001b[39m \u001b[43m    \u001b[49m\u001b[43mearly_stop_fn\u001b[49m\u001b[43m=\u001b[49m\u001b[43mearly_stop_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    688\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrials_save_file\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrials_save_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    689\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\NvanOort\\Code\\MADS\\DLDEPL\\portfolio-NTvanOort\\.venv\\Lib\\site-packages\\hyperopt\\fmin.py:586\u001b[39m, in \u001b[36mfmin\u001b[39m\u001b[34m(fn, space, algo, max_evals, timeout, loss_threshold, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin, points_to_evaluate, max_queue_len, show_progressbar, early_stop_fn, trials_save_file)\u001b[39m\n\u001b[32m    583\u001b[39m rval.catch_eval_exceptions = catch_eval_exceptions\n\u001b[32m    585\u001b[39m \u001b[38;5;66;03m# next line is where the fmin is actually executed\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m586\u001b[39m \u001b[43mrval\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexhaust\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    588\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m return_argmin:\n\u001b[32m    589\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(trials.trials) == \u001b[32m0\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\NvanOort\\Code\\MADS\\DLDEPL\\portfolio-NTvanOort\\.venv\\Lib\\site-packages\\hyperopt\\fmin.py:364\u001b[39m, in \u001b[36mFMinIter.exhaust\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    362\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mexhaust\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    363\u001b[39m     n_done = \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m.trials)\n\u001b[32m--> \u001b[39m\u001b[32m364\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmax_evals\u001b[49m\u001b[43m \u001b[49m\u001b[43m-\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_done\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mblock_until_done\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43masynchronous\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    365\u001b[39m     \u001b[38;5;28mself\u001b[39m.trials.refresh()\n\u001b[32m    366\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\NvanOort\\Code\\MADS\\DLDEPL\\portfolio-NTvanOort\\.venv\\Lib\\site-packages\\hyperopt\\fmin.py:300\u001b[39m, in \u001b[36mFMinIter.run\u001b[39m\u001b[34m(self, N, block_until_done)\u001b[39m\n\u001b[32m    297\u001b[39m     time.sleep(\u001b[38;5;28mself\u001b[39m.poll_interval_secs)\n\u001b[32m    298\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    299\u001b[39m     \u001b[38;5;66;03m# -- loop over trials and do the jobs directly\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m300\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mserial_evaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    302\u001b[39m \u001b[38;5;28mself\u001b[39m.trials.refresh()\n\u001b[32m    303\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.trials_save_file != \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\NvanOort\\Code\\MADS\\DLDEPL\\portfolio-NTvanOort\\.venv\\Lib\\site-packages\\hyperopt\\fmin.py:178\u001b[39m, in \u001b[36mFMinIter.serial_evaluate\u001b[39m\u001b[34m(self, N)\u001b[39m\n\u001b[32m    176\u001b[39m ctrl = base.Ctrl(\u001b[38;5;28mself\u001b[39m.trials, current_trial=trial)\n\u001b[32m    177\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m178\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdomain\u001b[49m\u001b[43m.\u001b[49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mspec\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctrl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    179\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    180\u001b[39m     logger.error(\u001b[33m\"\u001b[39m\u001b[33mjob exception: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m\"\u001b[39m % \u001b[38;5;28mstr\u001b[39m(e))\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\NvanOort\\Code\\MADS\\DLDEPL\\portfolio-NTvanOort\\.venv\\Lib\\site-packages\\hyperopt\\base.py:892\u001b[39m, in \u001b[36mDomain.evaluate\u001b[39m\u001b[34m(self, config, ctrl, attach_attachments)\u001b[39m\n\u001b[32m    883\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    884\u001b[39m     \u001b[38;5;66;03m# -- the \"work\" of evaluating `config` can be written\u001b[39;00m\n\u001b[32m    885\u001b[39m     \u001b[38;5;66;03m#    either into the pyll part (self.expr)\u001b[39;00m\n\u001b[32m    886\u001b[39m     \u001b[38;5;66;03m#    or the normal Python part (self.fn)\u001b[39;00m\n\u001b[32m    887\u001b[39m     pyll_rval = pyll.rec_eval(\n\u001b[32m    888\u001b[39m         \u001b[38;5;28mself\u001b[39m.expr,\n\u001b[32m    889\u001b[39m         memo=memo,\n\u001b[32m    890\u001b[39m         print_node_on_error=\u001b[38;5;28mself\u001b[39m.rec_eval_print_node_on_error,\n\u001b[32m    891\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m892\u001b[39m     rval = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpyll_rval\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    894\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(rval, (\u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;28mint\u001b[39m, np.number)):\n\u001b[32m    895\u001b[39m     dict_rval = {\u001b[33m\"\u001b[39m\u001b[33mloss\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mfloat\u001b[39m(rval), \u001b[33m\"\u001b[39m\u001b[33mstatus\u001b[39m\u001b[33m\"\u001b[39m: STATUS_OK}\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 57\u001b[39m, in \u001b[36mobjective\u001b[39m\u001b[34m(params)\u001b[39m\n\u001b[32m     46\u001b[39m \u001b[38;5;66;03m# Train the model using a custom train loop\u001b[39;00m\n\u001b[32m     47\u001b[39m trainer = Trainer(\n\u001b[32m     48\u001b[39m     model=model,\n\u001b[32m     49\u001b[39m     settings=settings,\n\u001b[32m   (...)\u001b[39m\u001b[32m     55\u001b[39m     device=device,\n\u001b[32m     56\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m57\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mloop\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     59\u001b[39m \u001b[38;5;66;03m# Save the trained model with a timestamp\u001b[39;00m\n\u001b[32m     60\u001b[39m tag = datetime.now().strftime(\u001b[33m\"\u001b[39m\u001b[33m%\u001b[39m\u001b[33mY\u001b[39m\u001b[33m%\u001b[39m\u001b[33mm\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[33m-\u001b[39m\u001b[33m%\u001b[39m\u001b[33mH\u001b[39m\u001b[33m%\u001b[39m\u001b[33mM\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\NvanOort\\Code\\MADS\\DLDEPL\\portfolio-NTvanOort\\.venv\\Lib\\site-packages\\mltrainer\\trainer.py:95\u001b[39m, in \u001b[36mTrainer.loop\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     93\u001b[39m epoch = \u001b[32m0\u001b[39m\n\u001b[32m     94\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m.settings.epochs), colour=\u001b[33m\"\u001b[39m\u001b[33m#1e4706\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m---> \u001b[39m\u001b[32m95\u001b[39m     train_loss = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtrainbatches\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     96\u001b[39m     metric_dict, test_loss = \u001b[38;5;28mself\u001b[39m.evalbatches()\n\u001b[32m     97\u001b[39m     \u001b[38;5;28mself\u001b[39m.report(epoch, train_loss, test_loss, metric_dict)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\NvanOort\\Code\\MADS\\DLDEPL\\portfolio-NTvanOort\\.venv\\Lib\\site-packages\\mltrainer\\trainer.py:124\u001b[39m, in \u001b[36mTrainer.trainbatches\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    122\u001b[39m     x, y = x.to(\u001b[38;5;28mself\u001b[39m.device), y.to(\u001b[38;5;28mself\u001b[39m.device)\n\u001b[32m    123\u001b[39m \u001b[38;5;28mself\u001b[39m.optimizer.zero_grad()  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m124\u001b[39m yhat = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    125\u001b[39m loss = \u001b[38;5;28mself\u001b[39m.loss_fn(yhat, y)\n\u001b[32m    126\u001b[39m loss.backward()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\NvanOort\\Code\\MADS\\DLDEPL\\portfolio-NTvanOort\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1734\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1735\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1736\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\NvanOort\\Code\\MADS\\DLDEPL\\portfolio-NTvanOort\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1742\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1743\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1744\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1745\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1746\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1747\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1749\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1750\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\NvanOort\\Code\\MADS\\DLDEPL\\portfolio-NTvanOort\\.venv\\Lib\\site-packages\\mltrainer\\imagemodels.py:146\u001b[39m, in \u001b[36mCNNblocks.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m    144\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m conv \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.convolutions:\n\u001b[32m    145\u001b[39m     x = conv(x)\n\u001b[32m--> \u001b[39m\u001b[32m146\u001b[39m x = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdense\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    147\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\NvanOort\\Code\\MADS\\DLDEPL\\portfolio-NTvanOort\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1734\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1735\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1736\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\NvanOort\\Code\\MADS\\DLDEPL\\portfolio-NTvanOort\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1742\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1743\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1744\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1745\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1746\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1747\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1749\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1750\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\NvanOort\\Code\\MADS\\DLDEPL\\portfolio-NTvanOort\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\container.py:250\u001b[39m, in \u001b[36mSequential.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    248\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[32m    249\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m250\u001b[39m         \u001b[38;5;28minput\u001b[39m = \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    251\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\NvanOort\\Code\\MADS\\DLDEPL\\portfolio-NTvanOort\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1734\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1735\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1736\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\NvanOort\\Code\\MADS\\DLDEPL\\portfolio-NTvanOort\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1742\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1743\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1744\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1745\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1746\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1747\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1749\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1750\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\NvanOort\\Code\\MADS\\DLDEPL\\portfolio-NTvanOort\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:125\u001b[39m, in \u001b[36mLinear.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    124\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) -> Tensor:\n\u001b[32m--> \u001b[39m\u001b[32m125\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mRuntimeError\u001b[39m: mat1 and mat2 shapes cannot be multiplied (64x80 and 3920x80)"
     ]
    }
   ],
   "source": [
    "best_result = fmin(\n",
    "    fn=objective,\n",
    "    space=search_space,\n",
    "    algo=tpe.suggest,\n",
    "    max_evals=3,\n",
    "    trials=Trials()\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After running this, you can look at the best_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_result"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLflow GUI\n",
    "MLflow has a really great dashboard.\n",
    "you can see it with the command:\n",
    "```bash\n",
    "mlflow server \\\n",
    "    --backend-store-uri sqlite:///mlflow.db \\\n",
    "    --host 127.0.0.1 \\ \n",
    "    --port 5000 \\\n",
    "```\n",
    "\n",
    "The `--backend-store-uri` argument specifies the location of the SQLite database file, which is used to store experiment metadata, such as parameters, metrics, and artifacts. \n",
    "We have initialized the experiment with `mlflow.set_tracking_uri(\"sqlite:///mlflow.db\")`, so `mlflow.db` is the location we need. \n",
    "\n",
    "`--host` tells the server we use our own machine (localhost), and `--port` specifies the port number on which the server will listen for incoming requests. In this case, we are using port 5000. Sometimes, you can have conflicts on a specific port and it could help to change the port (eg to 5001)\n",
    "\n",
    "Note that on a windows machine, the `\\` gives errors (because, why not, right) so for windows you might need to remove the `\\` and put everything on a single line.\n",
    "\n",
    "I have created a `Makefile` to automate these commands, but if it doesnt work (again, because you are on windows for example) you can just type the command by hand in your terminal.\n",
    "\n",
    "After starting this up, go to `http://127.0.0.1:5000` in your browser. You should see the MLflow UI, where you can explore your experiments, runs, and metrics. The UI provides a user-friendly way to visualize and compare different runs, making it easier to analyze the results of your hyperparameter optimization and model training."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
